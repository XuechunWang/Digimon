{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "DATASET_DIR = './data/'\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "SAVE_DIR = './'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "y = X['domain1_score']\n",
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum and Maximum Scores for each essay set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = [-1, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "maximum_scores = [-1, 12, 6, 3, 3, 4, 4, 30, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess all essays and convert them to feature vectors so that they can be fed into the RNN.\n",
    "\n",
    "These are all helper functions used to clean the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a 2-Layer LSTM Model. \n",
    "\n",
    "Note that instead of using sigmoid activation in the output layer we will use\n",
    "Relu since we are not normalising training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model on the dataset.\n",
    "\n",
    "We will use 5-Fold Cross Validation and measure the Quadratic Weighted Kappa for each fold.\n",
    "We will then calculate Average Kappa for all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10380/10380 [==============================] - 4s 416us/step - loss: 61.1237 - mean_absolute_error: 4.2532\n",
      "Epoch 2/50\n",
      "10380/10380 [==============================] - 3s 263us/step - loss: 37.6836 - mean_absolute_error: 3.4785\n",
      "Epoch 3/50\n",
      "10380/10380 [==============================] - 3s 263us/step - loss: 31.9497 - mean_absolute_error: 3.3812\n",
      "Epoch 4/50\n",
      "10380/10380 [==============================] - 3s 292us/step - loss: 29.7985 - mean_absolute_error: 3.3205\n",
      "Epoch 5/50\n",
      "10380/10380 [==============================] - 3s 288us/step - loss: 27.8840 - mean_absolute_error: 3.2331\n",
      "Epoch 6/50\n",
      "10380/10380 [==============================] - 3s 268us/step - loss: 26.2929 - mean_absolute_error: 3.1499\n",
      "Epoch 7/50\n",
      "10380/10380 [==============================] - 3s 284us/step - loss: 25.7488 - mean_absolute_error: 3.0381\n",
      "Epoch 8/50\n",
      "10380/10380 [==============================] - 3s 277us/step - loss: 23.2111 - mean_absolute_error: 2.8310\n",
      "Epoch 9/50\n",
      "10380/10380 [==============================] - 3s 277us/step - loss: 21.1451 - mean_absolute_error: 2.6701\n",
      "Epoch 10/50\n",
      "10380/10380 [==============================] - 3s 267us/step - loss: 18.8612 - mean_absolute_error: 2.5359\n",
      "Epoch 11/50\n",
      "10380/10380 [==============================] - 3s 265us/step - loss: 16.6250 - mean_absolute_error: 2.3776\n",
      "Epoch 12/50\n",
      "10380/10380 [==============================] - 3s 253us/step - loss: 16.0620 - mean_absolute_error: 2.3188\n",
      "Epoch 13/50\n",
      "10380/10380 [==============================] - 3s 244us/step - loss: 15.2966 - mean_absolute_error: 2.2698\n",
      "Epoch 14/50\n",
      "10380/10380 [==============================] - 3s 248us/step - loss: 14.3903 - mean_absolute_error: 2.1796\n",
      "Epoch 15/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 13.6209 - mean_absolute_error: 2.1367\n",
      "Epoch 16/50\n",
      "10380/10380 [==============================] - 3s 244us/step - loss: 13.1306 - mean_absolute_error: 2.0725\n",
      "Epoch 17/50\n",
      "10380/10380 [==============================] - 3s 244us/step - loss: 12.6189 - mean_absolute_error: 2.0439\n",
      "Epoch 18/50\n",
      "10380/10380 [==============================] - 3s 249us/step - loss: 12.1982 - mean_absolute_error: 1.9965\n",
      "Epoch 19/50\n",
      "10380/10380 [==============================] - 3s 245us/step - loss: 12.0727 - mean_absolute_error: 1.9668\n",
      "Epoch 20/50\n",
      "10380/10380 [==============================] - 3s 245us/step - loss: 12.0051 - mean_absolute_error: 1.9646\n",
      "Epoch 21/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 11.5172 - mean_absolute_error: 1.9302\n",
      "Epoch 22/50\n",
      "10380/10380 [==============================] - 3s 250us/step - loss: 10.3518 - mean_absolute_error: 1.8527\n",
      "Epoch 23/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 10.6624 - mean_absolute_error: 1.8631\n",
      "Epoch 24/50\n",
      "10380/10380 [==============================] - 3s 253us/step - loss: 10.5658 - mean_absolute_error: 1.8406\n",
      "Epoch 25/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 10.4105 - mean_absolute_error: 1.8115\n",
      "Epoch 26/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 9.8454 - mean_absolute_error: 1.7753\n",
      "Epoch 27/50\n",
      "10380/10380 [==============================] - 3s 248us/step - loss: 9.7585 - mean_absolute_error: 1.7790\n",
      "Epoch 28/50\n",
      "10380/10380 [==============================] - 3s 245us/step - loss: 9.8445 - mean_absolute_error: 1.7451\n",
      "Epoch 29/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 9.4335 - mean_absolute_error: 1.7131\n",
      "Epoch 30/50\n",
      "10380/10380 [==============================] - 3s 245us/step - loss: 9.4571 - mean_absolute_error: 1.7051\n",
      "Epoch 31/50\n",
      "10380/10380 [==============================] - 3s 245us/step - loss: 9.3514 - mean_absolute_error: 1.7151\n",
      "Epoch 32/50\n",
      "10380/10380 [==============================] - 3s 248us/step - loss: 9.1656 - mean_absolute_error: 1.6846\n",
      "Epoch 33/50\n",
      "10380/10380 [==============================] - 3s 244us/step - loss: 9.0450 - mean_absolute_error: 1.6911\n",
      "Epoch 34/50\n",
      "10380/10380 [==============================] - 3s 257us/step - loss: 8.8836 - mean_absolute_error: 1.6773\n",
      "Epoch 35/50\n",
      "10380/10380 [==============================] - 3s 248us/step - loss: 8.5946 - mean_absolute_error: 1.6383\n",
      "Epoch 36/50\n",
      "10380/10380 [==============================] - 3s 248us/step - loss: 8.5049 - mean_absolute_error: 1.6260\n",
      "Epoch 37/50\n",
      "10380/10380 [==============================] - 3s 282us/step - loss: 8.6284 - mean_absolute_error: 1.6460\n",
      "Epoch 38/50\n",
      "10380/10380 [==============================] - 3s 271us/step - loss: 8.8167 - mean_absolute_error: 1.6421\n",
      "Epoch 39/50\n",
      "10380/10380 [==============================] - 3s 269us/step - loss: 9.1101 - mean_absolute_error: 1.6570\n",
      "Epoch 40/50\n",
      "10380/10380 [==============================] - 3s 271us/step - loss: 8.5360 - mean_absolute_error: 1.6223\n",
      "Epoch 41/50\n",
      "10380/10380 [==============================] - 3s 269us/step - loss: 8.2943 - mean_absolute_error: 1.6129\n",
      "Epoch 42/50\n",
      "10380/10380 [==============================] - 3s 263us/step - loss: 8.6205 - mean_absolute_error: 1.6263\n",
      "Epoch 43/50\n",
      "10380/10380 [==============================] - 3s 263us/step - loss: 8.3740 - mean_absolute_error: 1.6096\n",
      "Epoch 44/50\n",
      "10380/10380 [==============================] - 3s 254us/step - loss: 8.5482 - mean_absolute_error: 1.6145\n",
      "Epoch 45/50\n",
      "10380/10380 [==============================] - 3s 247us/step - loss: 8.3121 - mean_absolute_error: 1.5959\n",
      "Epoch 46/50\n",
      "10380/10380 [==============================] - 3s 245us/step - loss: 8.3263 - mean_absolute_error: 1.6013\n",
      "Epoch 47/50\n",
      "10380/10380 [==============================] - 3s 249us/step - loss: 7.7462 - mean_absolute_error: 1.5603\n",
      "Epoch 48/50\n",
      "10380/10380 [==============================] - 3s 247us/step - loss: 8.3618 - mean_absolute_error: 1.5800\n",
      "Epoch 49/50\n",
      "10380/10380 [==============================] - 3s 247us/step - loss: 8.1021 - mean_absolute_error: 1.5671\n",
      "Epoch 50/50\n",
      "10380/10380 [==============================] - 3s 246us/step - loss: 8.2281 - mean_absolute_error: 1.5912\n",
      "Kappa Score: 0.9569833496059957\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 4s 409us/step - loss: 64.0217 - mean_absolute_error: 4.3643\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 39.5173 - mean_absolute_error: 3.4875\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 33.4803 - mean_absolute_error: 3.3876\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 3s 244us/step - loss: 31.4914 - mean_absolute_error: 3.3728\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 30.7005 - mean_absolute_error: 3.3432\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 28.6534 - mean_absolute_error: 3.2385\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 27.6621 - mean_absolute_error: 3.1246\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 25.5999 - mean_absolute_error: 2.9540\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 22.4424 - mean_absolute_error: 2.7617\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 20.4188 - mean_absolute_error: 2.6086\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 17.6801 - mean_absolute_error: 2.4447\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 16.7301 - mean_absolute_error: 2.3581\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 3s 259us/step - loss: 15.2634 - mean_absolute_error: 2.2663\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 14.8543 - mean_absolute_error: 2.2376\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 14.1981 - mean_absolute_error: 2.1647\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 3s 259us/step - loss: 13.5424 - mean_absolute_error: 2.1142\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 13.5285 - mean_absolute_error: 2.0917\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 13.1015 - mean_absolute_error: 2.0568\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 12.3553 - mean_absolute_error: 1.9883\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 12.0698 - mean_absolute_error: 1.9572\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 11.9403 - mean_absolute_error: 1.9584\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 11.2197 - mean_absolute_error: 1.8958\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 11.5555 - mean_absolute_error: 1.9195\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 10.9102 - mean_absolute_error: 1.8775\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 256us/step - loss: 10.7688 - mean_absolute_error: 1.8445\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 10.9769 - mean_absolute_error: 1.8316\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 10.0466 - mean_absolute_error: 1.7859\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 3s 269us/step - loss: 10.3710 - mean_absolute_error: 1.7812\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 9.8475 - mean_absolute_error: 1.7624\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 3s 256us/step - loss: 9.8721 - mean_absolute_error: 1.7619\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 9.5660 - mean_absolute_error: 1.7377\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 9.4292 - mean_absolute_error: 1.7283\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 9.5495 - mean_absolute_error: 1.7173\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 3s 254us/step - loss: 9.5535 - mean_absolute_error: 1.7290\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 9.2336 - mean_absolute_error: 1.6854\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 9.1015 - mean_absolute_error: 1.6895\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 9.2340 - mean_absolute_error: 1.6809\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 9.1136 - mean_absolute_error: 1.6814\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 243us/step - loss: 9.0121 - mean_absolute_error: 1.6617\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 9.1009 - mean_absolute_error: 1.6529\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.7578 - mean_absolute_error: 1.6425\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.7942 - mean_absolute_error: 1.6383\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.8305 - mean_absolute_error: 1.6401\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 8.8121 - mean_absolute_error: 1.6374\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 8.5045 - mean_absolute_error: 1.6256\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.3517 - mean_absolute_error: 1.6221\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 8.2509 - mean_absolute_error: 1.6062\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 3s 260us/step - loss: 8.5090 - mean_absolute_error: 1.5934\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 8.0501 - mean_absolute_error: 1.5860\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 8.4379 - mean_absolute_error: 1.6020\n",
      "Kappa Score: 0.9659206858385979\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 62.9005 - mean_absolute_error: 4.2945\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 38.9111 - mean_absolute_error: 3.4769\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 3s 295us/step - loss: 32.1912 - mean_absolute_error: 3.3709\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 3s 276us/step - loss: 30.4288 - mean_absolute_error: 3.3472\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 3s 283us/step - loss: 29.1292 - mean_absolute_error: 3.3127\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 3s 272us/step - loss: 27.2783 - mean_absolute_error: 3.1990\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 3s 270us/step - loss: 26.2234 - mean_absolute_error: 3.0647\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 25.2885 - mean_absolute_error: 2.9448\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 3s 265us/step - loss: 23.4081 - mean_absolute_error: 2.8019\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 3s 263us/step - loss: 20.9391 - mean_absolute_error: 2.6153\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 18.8836 - mean_absolute_error: 2.4926\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 3s 267us/step - loss: 17.7349 - mean_absolute_error: 2.3989\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 16.4862 - mean_absolute_error: 2.3159\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 15.3535 - mean_absolute_error: 2.2428\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 3s 256us/step - loss: 14.8637 - mean_absolute_error: 2.2039\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 13.7405 - mean_absolute_error: 2.1114\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 254us/step - loss: 13.6270 - mean_absolute_error: 2.0811\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 12.7311 - mean_absolute_error: 2.0277\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 254us/step - loss: 12.5843 - mean_absolute_error: 2.0123\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 12.0050 - mean_absolute_error: 1.9916\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 3s 257us/step - loss: 11.8586 - mean_absolute_error: 1.9646\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 11.2580 - mean_absolute_error: 1.9171\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 267us/step - loss: 11.3763 - mean_absolute_error: 1.9163\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 11.0316 - mean_absolute_error: 1.8879\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 257us/step - loss: 10.6392 - mean_absolute_error: 1.8346\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 10.6598 - mean_absolute_error: 1.8473\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 10.2414 - mean_absolute_error: 1.8032\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 3s 274us/step - loss: 10.6074 - mean_absolute_error: 1.8134\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 3s 256us/step - loss: 10.0539 - mean_absolute_error: 1.7683\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 9.9205 - mean_absolute_error: 1.7607\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 9.9766 - mean_absolute_error: 1.7601\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 270us/step - loss: 9.7448 - mean_absolute_error: 1.7291\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 9.2694 - mean_absolute_error: 1.6929\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 3s 276us/step - loss: 9.1574 - mean_absolute_error: 1.6922\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 9.4766 - mean_absolute_error: 1.7132\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 269us/step - loss: 9.3584 - mean_absolute_error: 1.6831\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 3s 269us/step - loss: 9.4095 - mean_absolute_error: 1.6711\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 3s 263us/step - loss: 8.9539 - mean_absolute_error: 1.6572\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 8.6278 - mean_absolute_error: 1.6386\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 9.1275 - mean_absolute_error: 1.6680\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 8.5733 - mean_absolute_error: 1.6384\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 8.8799 - mean_absolute_error: 1.6363\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 8.8260 - mean_absolute_error: 1.6353\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 8.7216 - mean_absolute_error: 1.6221\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 8.8220 - mean_absolute_error: 1.6367\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.7268 - mean_absolute_error: 1.6157\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 8.6126 - mean_absolute_error: 1.6121\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 8.5615 - mean_absolute_error: 1.6125\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 8.4072 - mean_absolute_error: 1.5856\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 8.6606 - mean_absolute_error: 1.6063\n",
      "Kappa Score: 0.9624834331042\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 5s 445us/step - loss: 65.6900 - mean_absolute_error: 4.3886\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 39.8261 - mean_absolute_error: 3.5114\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 33.4224 - mean_absolute_error: 3.4131\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 31.4932 - mean_absolute_error: 3.3843\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 29.5924 - mean_absolute_error: 3.2967\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 28.8380 - mean_absolute_error: 3.2099\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 26.5579 - mean_absolute_error: 3.0270\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 22.9977 - mean_absolute_error: 2.7959\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 20.7320 - mean_absolute_error: 2.6488\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 3s 243us/step - loss: 19.3136 - mean_absolute_error: 2.5558\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 17.8324 - mean_absolute_error: 2.4243\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 16.3224 - mean_absolute_error: 2.3369\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 16.2928 - mean_absolute_error: 2.3181\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 15.5162 - mean_absolute_error: 2.2211\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 13.8212 - mean_absolute_error: 2.1348\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 14.4315 - mean_absolute_error: 2.1404\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 243us/step - loss: 13.7328 - mean_absolute_error: 2.1044\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 13.1612 - mean_absolute_error: 2.0534\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 12.6199 - mean_absolute_error: 2.0131\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 12.5186 - mean_absolute_error: 1.9993\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 12.1298 - mean_absolute_error: 1.9667\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 12.6947 - mean_absolute_error: 1.9594\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 11.5813 - mean_absolute_error: 1.9036\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 11.0486 - mean_absolute_error: 1.8687\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 11.2852 - mean_absolute_error: 1.8719\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 3s 252us/step - loss: 10.8829 - mean_absolute_error: 1.8376\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 10.5005 - mean_absolute_error: 1.8034\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 10.4229 - mean_absolute_error: 1.8026\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 3s 257us/step - loss: 10.3069 - mean_absolute_error: 1.7860\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 3s 271us/step - loss: 10.0097 - mean_absolute_error: 1.7829\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 254us/step - loss: 10.3880 - mean_absolute_error: 1.7808\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 272us/step - loss: 10.0574 - mean_absolute_error: 1.7620\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 3s 260us/step - loss: 10.1352 - mean_absolute_error: 1.7556\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 3s 265us/step - loss: 9.5206 - mean_absolute_error: 1.7251\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 266us/step - loss: 9.4193 - mean_absolute_error: 1.7228\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 9.4014 - mean_absolute_error: 1.6962\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 9.6003 - mean_absolute_error: 1.7110\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 9.5912 - mean_absolute_error: 1.7020\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 257us/step - loss: 9.4375 - mean_absolute_error: 1.6990\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.8492 - mean_absolute_error: 1.6676\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 8.9450 - mean_absolute_error: 1.6493\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 9.0979 - mean_absolute_error: 1.6552\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 9.2039 - mean_absolute_error: 1.6778\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 3s 269us/step - loss: 8.9123 - mean_absolute_error: 1.6514\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 271us/step - loss: 8.8976 - mean_absolute_error: 1.6533\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 8.6528 - mean_absolute_error: 1.6317\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 3s 271us/step - loss: 8.9333 - mean_absolute_error: 1.6394\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 3s 273us/step - loss: 8.6130 - mean_absolute_error: 1.6092\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 8.4807 - mean_absolute_error: 1.6106\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 8.4048 - mean_absolute_error: 1.6148\n",
      "Kappa Score: 0.957083745477981\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 63.8091 - mean_absolute_error: 4.3430\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 38.4076 - mean_absolute_error: 3.4598\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 3s 256us/step - loss: 32.1988 - mean_absolute_error: 3.3564\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 29.5834 - mean_absolute_error: 3.3075\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 3s 256us/step - loss: 27.9552 - mean_absolute_error: 3.2433\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 3s 254us/step - loss: 27.4482 - mean_absolute_error: 3.1950\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 26.2425 - mean_absolute_error: 3.0556\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 24.0053 - mean_absolute_error: 2.9114\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 22.6613 - mean_absolute_error: 2.8036\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 3s 275us/step - loss: 20.9475 - mean_absolute_error: 2.7017\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 3s 280us/step - loss: 19.7591 - mean_absolute_error: 2.5909\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 3s 267us/step - loss: 18.1344 - mean_absolute_error: 2.4733\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 16.4336 - mean_absolute_error: 2.3395\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 15.0641 - mean_absolute_error: 2.2517\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 14.2755 - mean_absolute_error: 2.1733\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 13.4591 - mean_absolute_error: 2.1126\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 13.3895 - mean_absolute_error: 2.0863\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 12.8434 - mean_absolute_error: 2.0516\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 12.5617 - mean_absolute_error: 2.0174\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 11.7485 - mean_absolute_error: 1.9609\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 11.6216 - mean_absolute_error: 1.9219\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 3s 259us/step - loss: 11.0626 - mean_absolute_error: 1.9119\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 10.8145 - mean_absolute_error: 1.8777\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 10.8864 - mean_absolute_error: 1.8454\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 10.4963 - mean_absolute_error: 1.8174\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 10.6422 - mean_absolute_error: 1.7947\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 9.7564 - mean_absolute_error: 1.7600\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 9.7473 - mean_absolute_error: 1.7589\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 3s 258us/step - loss: 9.8094 - mean_absolute_error: 1.7425\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 9.6040 - mean_absolute_error: 1.7214\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 9.3283 - mean_absolute_error: 1.6894\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 9.5503 - mean_absolute_error: 1.7074\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 9.0609 - mean_absolute_error: 1.6848\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 9.7159 - mean_absolute_error: 1.7067\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 9.1968 - mean_absolute_error: 1.6719\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 9.0715 - mean_absolute_error: 1.6734\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 3s 245us/step - loss: 9.0718 - mean_absolute_error: 1.6514\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 8.8822 - mean_absolute_error: 1.6521\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 8.7483 - mean_absolute_error: 1.6455\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 8.7378 - mean_absolute_error: 1.6333\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 8.2836 - mean_absolute_error: 1.6037\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 8.4733 - mean_absolute_error: 1.6233\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 8.9157 - mean_absolute_error: 1.6349\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 8.1467 - mean_absolute_error: 1.5742\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 7.9221 - mean_absolute_error: 1.5677\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.0574 - mean_absolute_error: 1.5848\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 8.4741 - mean_absolute_error: 1.5959\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 8.3645 - mean_absolute_error: 1.5874\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 8.0779 - mean_absolute_error: 1.5779\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 7.6595 - mean_absolute_error: 1.5422\n",
      "Kappa Score: 0.9569604278342079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cv = KFold(len(X), n_folds=5, shuffle=True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv:\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    # Save any one of the 8 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save('./model_weights/final_lstm.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avg. Kappa Score is 0.961 which is the highest we have ever seen on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kappa score after a 5-fold cross validation:  0.9613\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
